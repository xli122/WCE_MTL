{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c8b73d-23c7-473e-8d56-b388656969cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model already use CUDA to accelerate the inference speed.\n",
      "\n",
      " Please put all your data into the data folder\n",
      "filename : d369e4f163df4aba_86014.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : 04a78ef00c5245e0_11219.jpg, prediction: angiectasia\n",
      "\n",
      "filename : d369e4f163df4aba_86013.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : 8ebf0e483cac48d6_1209.jpg, prediction: ulcer\n",
      "\n",
      "filename : d369e4f163df4aba_86065.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : 8ebf0e483cac48d6_1210.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_86103.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_12010.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_12016.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_12031.jpg, prediction: blood_fresh_hematin\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename : d369e4f163df4aba_12067.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_12076.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13298.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13314.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13316.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13328.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13354.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13355.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13356.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13361.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13368.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13372.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13374.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13406.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13410.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13416.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13436.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13465.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13475.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13478.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13487.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13500.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13504.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13511.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_13527.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_14192.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_14194.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_14197.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_14202.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_14208.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_14238.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_14248.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_2105.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_2111.jpg, prediction: blood_fresh_hematin\n",
      "\n",
      "filename : d369e4f163df4aba_86012.jpg, prediction: blood_fresh_hematin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Inference(model, image_dir):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5969, 0.3670, 0.1840),\n",
    "                            std=(0.1834, 0.1313, 0.0797))\n",
    "    ])\n",
    "    model.eval()\n",
    "    classname = [\"angiectasia\", \"blood_fresh_hematin\", \"erosion\", \"erythema\", \"foreign_body\",\n",
    "              \"lymphangiectasia\", \"normal_clean_mucosa\", \"polyp\", \"reduced_mucosal_view\", \"ulcer\"]\n",
    "    for filename in os.listdir(image_dir):\n",
    "        image_path = os.path.join(image_dir,filename)\n",
    "        rgb_img = plt.imread(image_path)\n",
    "        rgb_img = (rgb_img * 255).astype(np.uint8)\n",
    "        input_tensor = transform(rgb_img)\n",
    "        input_tensor = torch.tensor(np.expand_dims(input_tensor, 0))\n",
    "        input_tensor = input_tensor.to(\"cuda:0\")\n",
    "        output,_ = model(input_tensor)\n",
    "        value, indice = torch.max(output,1)\n",
    "        # print(f\"output = {output}, value, indice = {value, indice}\")\n",
    "        print(f\"filename : {filename}, prediction: {classname[indice.item()]}\\n\")\n",
    "    return\n",
    "\n",
    "model = torch.load(\"./ModelTripletMTL_datasetKvasirCapule10classes811_testacc0.9940_f1score0.9647_modelResNext50_32x4d_bs128_seed42_epochs30_optimSGD_lr0.01.pt\")\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5969, 0.3670, 0.1840),\n",
    "                            std=(0.1834, 0.1313, 0.0797))\n",
    "    ])\n",
    "print(\"The model already use CUDA to accelerate the inference speed.\")\n",
    "print(\"\\n Please put all your WCE image into the data folder\")\n",
    "Inference(model, image_dir=\"./data/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
